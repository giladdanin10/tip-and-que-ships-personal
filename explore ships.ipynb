{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "from display_aux import *\n",
    "from ships import SHIPS\n",
    "from df_aux import *\n",
    "from time_aux import *\n",
    "from file_aux import *\n",
    "from plot_aux import *\n",
    "from parse_aux import *\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ships = SHIPS()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options to show all rows and columns\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['input_csv_file_name_full'] = 'C:\\\\gilad\\\\work\\\\tip_and_que\\\\data\\\\AIS\\\\Combined\\\\Spire_AIS_Combined_All_20231101_1106_000000000000.csv'\n",
    "# params['input_csv_file_name_full'] = 'debug_data_base.csv'\n",
    "\n",
    "params['columns_list_keep'] = None\n",
    "params['filter_vessels_df_dic'] = {\n",
    "        'max_time_diff[mins]':['<=',30]\n",
    "        }\n",
    "params['reload_level'] = 1\n",
    "params['reload_df_filt'] = False\n",
    "params['reload_vessels'] = True\n",
    "params['save_folder_base'] = './pkl'\n",
    "\n",
    "params['export_to_excel'] = False\n",
    "params['ana_vessel_name'] = 'EYVAN'\n",
    "# params['df_filter_dic'] = {'position_timestamp':['<=','2023-11-01 02:00:00+0000']}\n",
    "params['df_filter_dic'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_row_data\n",
      "----------------\n",
      "load df from ./pkl/Spire_AIS_Combined_All_20231101_1106_000000000000/df_org.pkl\n",
      "filter_df\n",
      "----------------\n",
      "load df from ./pkl/Spire_AIS_Combined_All_20231101_1106_000000000000/df_org.pkl\n",
      "save df to ./pkl/Spire_AIS_Combined_All_20231101_1106_000000000000/df_filt.pkl\n"
     ]
    }
   ],
   "source": [
    "save_folder = params['save_folder_base']+'/'+ get_file_base_name(params['input_csv_file_name_full'])\n",
    "df = ships.load_raw_data(params['input_csv_file_name_full'],reload_level=params['reload_level'],save_folder=save_folder)\n",
    "\n",
    "# filter_df\n",
    "df = ships.prepare_df(df,reload_level=params['reload_level'],df_filter_dic=params['df_filter_dic'],save_folder=save_folder,columns_list_keep=params['columns_list_keep'])\n",
    "\n",
    "# data_dic = ships.create_data_dic(df,reload_level=params['reload_level'],save_folder=save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-11-01 00:00:00+0000', tz='UTC')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-11-01 01:27:53+0000', tz='UTC')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.time.min())\n",
    "display(df.time.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# def time_diff_convert(time_diff, units='secs'):\n",
    "#     if units == 'secs':\n",
    "#         return time_diff.dt.total_seconds()\n",
    "#     # Add other unit conversions if needed\n",
    "#     return time_diff\n",
    "\n",
    "# def handle_common_time_rows_in_df(df, time_column='time', ID_columns=[]):\n",
    "\n",
    "#     # handle a none list input \n",
    "#     if (not isinstance(ID_columns,list)):\n",
    "#         ID_columns = [ID_columns]\n",
    "\n",
    "#     # Check if the specified columns exist in the DataFrame\n",
    "#     missing_columns = [col for col in ID_columns + [time_column] if col not in df.columns]\n",
    "#     if missing_columns:\n",
    "#         raise ValueError(f\"Missing columns in DataFrame: {', '.join(missing_columns)}\")\n",
    "    \n",
    "#     # Initialize a counter for the number of common time chunks found\n",
    "#     common_time_chunks_count = 0\n",
    "    \n",
    "#     # Get the total number of chunks\n",
    "#     total_chunks = df.groupby(ID_columns).ngroups\n",
    "    \n",
    "#     # Function to handle rows with common time values in chunks defined by ID_columns\n",
    "#     def combine_rows(chunk, chunk_number):\n",
    "#         nonlocal common_time_chunks_count\n",
    "        \n",
    "#         # Sort the chunk by the time_column\n",
    "#         chunk = chunk.sort_values(by=time_column)\n",
    "        \n",
    "#         # Calculate the time differences in seconds\n",
    "#         time_diff = chunk[time_column].diff()\n",
    "#         time_diff = time_diff_convert(time_diff, units='secs')\n",
    "#         zero_diff_line_numbers = np.where(time_diff == 0)[0]\n",
    "        \n",
    "#         # Initialize a list to hold the indices of rows to be dropped\n",
    "#         indices_to_drop = []\n",
    "        \n",
    "#         # Iterate over the indices with zero time differences and combine rows\n",
    "#         for line_number in zero_diff_line_numbers:\n",
    "#             # Ensure we have at least two rows to combine\n",
    "#             if line_number > 0:\n",
    "#                 combined_row = chunk.iloc[line_number].combine_first(chunk.iloc[line_number - 1])\n",
    "                \n",
    "#                 # Place the combined row at the index of the first row in the group\n",
    "#                 first_index = chunk.index[line_number - 1]\n",
    "#                 df.loc[first_index] = combined_row\n",
    "                \n",
    "#                 # Add the index of the current row to the drop list\n",
    "#                 indices_to_drop.append(chunk.index[line_number])\n",
    "                \n",
    "#                 common_time_chunks_count += 1  # Increment the counter\n",
    "        \n",
    "#         # Drop the rows that have been combined\n",
    "#         if (len(indices_to_drop)!=0):\n",
    "#             df.drop(indices_to_drop, inplace=True)\n",
    "        \n",
    "#         # Print progress every 1000 chunks\n",
    "#         if chunk_number % 10 == 0:\n",
    "#             print(f\"Processed chunk {chunk_number} out of {total_chunks}\")\n",
    "\n",
    "#     # Apply the function to each group defined by ID_columns\n",
    "#     for chunk_number, (_, chunk) in enumerate(df.groupby(ID_columns, group_keys=False), start=1):\n",
    "#         combine_rows(chunk, chunk_number)\n",
    "\n",
    "#     print(f\"Number of common time chunks found: {common_time_chunks_count}\")\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# # Sample DataFrame for testing\n",
    "# data = {\n",
    "#     'ID': [1, 1, 1, 2, 2],\n",
    "#     'time': ['2023-01-01 12:00', '2023-01-01 12:00', '2023-01-02 13:00', '2023-01-03 14:00', '2023-01-03 14:00'],\n",
    "#     'value': [10, np.nan, 30, 40, np.nan],\n",
    "#     'value2': [np.nan, 20, 30, np.nan, 50]\n",
    "# }\n",
    "# # df = pd.DataFrame(data)\n",
    "# # df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "# # Call the function\n",
    "# # df = handle_common_time_rows_in_df(df, time_column='time', ID_columns=['mmsi'])\n",
    "\n",
    "# # info_df['min_time_diff[mins]']==0\n",
    "# # item_df = get_item_df(df,item=412888888)\n",
    "\n",
    "# # item_df = handle_common_time_rows_in_df(item_df,ID_columns=['mmsi'])        \n",
    "# # item_df = handle_common_time_rows_in_df(item_df,ID_columns=['mmsi'])        \n",
    "\n",
    "# # print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map the mmsi's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create item_dic\n",
      "create info_df\n",
      "processing name 0 out of 1000\n"
     ]
    }
   ],
   "source": [
    "# def get_item_df(data,item,item_type='mmsi',sort_columns=None):\n",
    "# def get_item_df(data, item, **params):\n",
    "#     default_params = {\n",
    "#         'item_type': {'default': 'name', 'optional': {'name','mmsi'}},\n",
    "#         'sort_columns': {'default': None}\n",
    "#     }\n",
    "\n",
    "#     params = parse_func_params(params, default_params)\n",
    "\n",
    "#     if isinstance(data, dict):\n",
    "#         df_filt = data[item]\n",
    "#     else:\n",
    "#         df_filt = data.loc[data[params.item_type] == item]\n",
    "\n",
    "#     if params.sort_columns is not None:\n",
    "#         parse_func_params(params.sort_columns, df_filt.columns)  # Assuming parse_func_params is defined\n",
    "\n",
    "#         df_filt = df_filt.sort_values(by=params.sort_columns)\n",
    "\n",
    "#     return df_filt\n",
    "\n",
    "\n",
    "\n",
    "def get_item_df(data,item,**params):\n",
    "    default_params = {\n",
    "        'item_type': {'default': 'name', 'optional': {'name','mmsi'}},\n",
    "        'sort_columns':{'default':None}\n",
    "    }\n",
    "\n",
    "    params = parse_func_params(params, default_params)\n",
    "\n",
    "\n",
    "\n",
    "    if (isinstance(data,dict)):\n",
    "        df_filt = data[item]\n",
    "    else:\n",
    "        df_filt = data.loc[df[params['item_type']]==item]\n",
    "\n",
    "\n",
    "    # df_filt = handle_common_time_rows_in_df(df_filt,ID_columns=item_type)\n",
    "\n",
    "    if (params['sort_columns'] is not None):\n",
    "        parse_parameter(params['sort_columns'],df.columns)        \n",
    "\n",
    "        df_filt = df_filt.sort_values(by=params['sort_columns'])\n",
    "\n",
    "    return df_filt\n",
    "\n",
    "\n",
    "\n",
    "# def get_item_data_stats(item_data,item_type=None,id_column_check=[]):\n",
    "def get_item_data_stats(item_data,**params):\n",
    "    default_params = {\n",
    "        'item_type': {'default': 'name', 'optional': {'name','mmsi'}},\n",
    "        'id_column_check': {'default': []}\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        params = parse_func_params(params, default_params)\n",
    "    except ValueError as e:\n",
    "        print(e)  # Print the exception message with calling stack path\n",
    "        return None\n",
    "\n",
    "\n",
    "    if (not isinstance(params['id_column_check'],list)):\n",
    "        params['id_column_check'] = [params['id_column_check']]\n",
    "\n",
    "    stats_dic = {\n",
    "        params['item_type']:item_data[params['item_type']].unique().tolist(),\n",
    "        'len': [item_data.shape[0]],  # Scalar value wrapped in a list\n",
    "        'min_time':min(item_data['time']),\n",
    "        'max_time':max(item_data['time']),\n",
    "        'total_time':max(item_data['time'])- min(item_data['time']),\n",
    "        'min_time_diff[mins]': round(np.min(time_diff_convert(item_data['time'].diff()))),\n",
    "        'max_time_diff[mins]': round(np.max(time_diff_convert(item_data['time'].diff()))),\n",
    "        'mean_time_diff[mins]': round(np.mean(time_diff_convert(item_data['time'].diff()))),\n",
    "        'min_longitude':(min(item_data['longitude'])),\n",
    "        'max_longitude':(max(item_data['longitude'])),\n",
    "        'min_latitude':(min(item_data['latitude'])),\n",
    "        'max_latitude':(max(item_data['latitude'])),\n",
    "    }\n",
    "    stats_dic['span_longitude']  = stats_dic['max_longitude']-stats_dic['min_longitude']\n",
    "    stats_dic['span_latitude']  = stats_dic['max_latitude']-stats_dic['min_latitude']\n",
    "\n",
    "    for column in params['id_column_check']:\n",
    "        stats_dic[f'num_{column}s'] = item_data[column].unique().shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    return stats_dic\n",
    "\n",
    "\n",
    "\n",
    "# def create_info_df(df,num_lines = None,item_type='mmsi',id_column_check='name'):\n",
    "def create_info_df(df,**params):\n",
    "    default_params = {\n",
    "        'item_type': {'default': 'name', 'optional': {'name','mmsi'}},\n",
    "        'num_lines': {'default': None},\n",
    "        'id_column_check': {'default': []}\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        params = parse_func_params(params, default_params)\n",
    "    except ValueError as e:\n",
    "        print(e)  # Print the exception message with calling stack path\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print ('create item_dic')\n",
    "    groups = df.groupby(params['item_type'])\n",
    "    item_dict = {name: group for name, group in groups}\n",
    "\n",
    "    print('create info_df')\n",
    "\n",
    "    info_df = pd.DataFrame()\n",
    "    prob_mmsi = []\n",
    "    item_list = df[params['item_type']].unique()\n",
    "\n",
    "    if (params['num_lines'] != None):\n",
    "        item_list = item_list[:params['num_lines']]\n",
    "\n",
    "\n",
    "    for i, item in enumerate(item_list):\n",
    "        \n",
    "        if (i % 1000 == 0):\n",
    "            print(f\"processing {params['item_type']} {i} out of {len(item_list)}\")\n",
    "        # item_data = get_item_df(item_dict,item,item_type=item_type)  # Assuming get_item_data is defined elsewhere\n",
    "        item_data = get_item_df(item_dict,item,**params)  # Assuming get_item_data is defined elsewhere\n",
    "\n",
    "\n",
    "        item = item_data[params['item_type']].iloc[0]\n",
    "\n",
    "        if (item_data.shape[0]==1):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # ships_df_line = pd.DataFrame(get_item_data_stats(item_data,item_type=item_type,id_column_check=id_column_check),index=[item])\n",
    "            ships_df_line = pd.DataFrame(get_item_data_stats(item_data,**params),index=[item])\n",
    "\n",
    "        except Exception as e:\n",
    "            # Print the exception message\n",
    "            print(item)\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            # Optionally, you can log the error or perform other actions here\n",
    "            # Exit the program\n",
    "            sys.exit(1)\n",
    "\n",
    "\n",
    "        info_df = pd.concat([info_df, ships_df_line])\n",
    "\n",
    "    info_df = info_df.sort_values(by='len', ascending=False)\n",
    "\n",
    "    # info_df = info_df.reset_index(drop=True)\n",
    "    return info_df\n",
    "\n",
    "\n",
    "\n",
    "# example\n",
    "ship_data = get_item_df(df,'AOS VISION',item_type='name')\n",
    "params = {'item_type': 'name'}\n",
    "ship_data = get_item_df(df,'AOS VISION',**params)\n",
    "data_stats = get_item_data_stats(ship_data)\n",
    "info_df = create_info_df(df,num_lines=1000,item_type='name',id_column_check=['mmsi'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "get_item_df: Invalid value 'name1' for parameter 'item_type'. Allowed values are ['mmsi', 'name'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# example\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# ship_data = get_item_df(df,2335222)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m ship_data \u001b[38;5;241m=\u001b[39m get_item_df(df,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAOS VISION\u001b[39m\u001b[38;5;124m'\u001b[39m,item_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m, in \u001b[0;36mget_item_df\u001b[1;34m(data, item, **params)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_item_df\u001b[39m(data,item,\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m      3\u001b[0m     default_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_type\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptional\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmmsi\u001b[39m\u001b[38;5;124m'\u001b[39m}},\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msort_columns\u001b[39m\u001b[38;5;124m'\u001b[39m:{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m      6\u001b[0m     }\n\u001b[1;32m----> 8\u001b[0m     params \u001b[38;5;241m=\u001b[39m parse_func_params(params, default_params)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(data,\u001b[38;5;28mdict\u001b[39m)):\n\u001b[0;32m     13\u001b[0m         df_filt \u001b[38;5;241m=\u001b[39m data[item]\n",
      "File \u001b[1;32mc:\\gilad\\work\\tip_and_que\\code\\tip-and-que-ships-personal\\parse_aux.py:49\u001b[0m, in \u001b[0;36mparse_func_params\u001b[1;34m(params, default_params)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# Validate parameter value against allowed_values if provided\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allowed_values \u001b[38;5;129;01mand\u001b[39;00m param_value \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_values:\n\u001b[1;32m---> 49\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcalling_func_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Invalid value \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Allowed values are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(allowed_values)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m     parsed_params[param_name] \u001b[38;5;241m=\u001b[39m param_value\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed_params\n",
      "\u001b[1;31mValueError\u001b[0m: get_item_df: Invalid value 'name1' for parameter 'item_type'. Allowed values are ['mmsi', 'name']."
     ]
    }
   ],
   "source": [
    "# example\n",
    "# ship_data = get_item_df(df,2335222)\n",
    "# info_df = create_info_df(df,num_lines=1000,item_type='name',id_column_check=['mmsi'])\n",
    "# info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handle mutiple names per mmsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subplot_scheme(axes_size=(5, 2), num_axes=1, max_axes_in_row=4):\n",
    "    \"\"\"\n",
    "    Creates a subplot scheme and returns an array of axes.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    axes_size : tuple\n",
    "        Size of each individual subplot (width, height).\n",
    "\n",
    "    num_axes : int\n",
    "        Total number of subplots to create.\n",
    "\n",
    "    max_axes_in_row : int, optional\n",
    "        Maximum number of subplots in a row. Default is 4.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        The created figure.\n",
    "\n",
    "    axes : array-like of matplotlib.axes.Axes\n",
    "        Array of created subplot axes.\n",
    "    \"\"\"\n",
    "    # Calculate the number of rows and columns\n",
    "    num_cols = min(max_axes_in_row, num_axes)\n",
    "    num_rows = (num_axes + num_cols - 1) // num_cols  # Ceiling division to ensure all axes fit\n",
    "\n",
    "    # Calculate figure size based on individual axes size\n",
    "    fig_width = axes_size[0] * num_cols\n",
    "    fig_height = axes_size[1] * num_rows\n",
    "\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(fig_width, fig_height), constrained_layout=True)\n",
    "    \n",
    "    # Flatten the axes array if there are multiple rows or columns\n",
    "    if num_rows * num_cols > 1:\n",
    "        axes = axes.flatten()\n",
    "    else:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for i in range(num_axes, len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    return fig, axes[:num_axes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_parameter(parameter, allowed_values):\n",
    "    \"\"\"\n",
    "    Example function that only accepts specific values for its parameter.\n",
    "\n",
    "    Parameters:\n",
    "    - parameter: str, the input parameter which must be one of the allowed values.\n",
    "    - allowed_values: list, the set of allowed values for the parameter.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: if the parameter is not in the allowed values.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if (isinstance(parameter,list)):\n",
    "        for value in parameter:\n",
    "            if value not in allowed_values:\n",
    "                raise ValueError(f\"Invalid value '{value}'. Allowed values are: {allowed_values}\")\n",
    "    else: \n",
    "        if parameter not in allowed_values:\n",
    "            raise ValueError(f\"Invalid value '{parameter}'. Allowed values are: {allowed_values}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def plot_df_columns(df, columns=None, axes=None, fig_size=(10, 6), title='Plot',x_data_type='index',time_column = 'time',normalize=False,xlim_val  = None, ylim_val = None):\n",
    "    \"\"\"\n",
    "    Plots specified columns from a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing the data.\n",
    "    - columns: list of column names to plot. If None, all columns are plotted.\n",
    "    - axes: matplotlib axes object. If None, a new figure and axes are created.\n",
    "    - fig_size: tuple, the size of the figure.\n",
    "    - title: str, the title of the plot.\n",
    "    \n",
    "    Returns:\n",
    "    - axes: matplotlib axes object with the plot.\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        raise ValueError(\"columns is empty\")\n",
    "    \n",
    "    elif not isinstance(columns,list):\n",
    "        columns = [columns]\n",
    "    \n",
    "    parse_parameter(columns,df.columns)\n",
    "    parse_parameter(x_data_type,['index','time'])\n",
    "\n",
    "    if axes is None:\n",
    "        fig, axes = plt.subplots(figsize=fig_size)\n",
    "        created_fig = True\n",
    "    else:\n",
    "        created_fig = False\n",
    "\n",
    "    if (x_data_type=='index'):\n",
    "        x_data = range(df.shape[0])\n",
    "\n",
    "    elif (x_data_type=='time'):\n",
    "        x_data = df[time_column]\n",
    "    \n",
    "\n",
    "    for column in columns:\n",
    "        if (normalize):\n",
    "            y_data = (df[column]-df[column].min())/(df[column].max()-df[column].min())\n",
    "        else:\n",
    "            y_data = df[column]\n",
    "\n",
    "        axes.plot(x_data, y_data, label=column)\n",
    "    \n",
    "    if (x_data_type=='time'):\n",
    "        axes.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "        for label in axes.get_xticklabels():\n",
    "            label.set_rotation(45)\n",
    "            label.set_horizontalalignment('right')\n",
    "            label.set_fontsize(8)\n",
    "        \n",
    "\n",
    "\n",
    "    axes.set_title(title)\n",
    "    axes.legend()\n",
    "    # if (xlim_val is not None):\n",
    "    #     axes.xlim(xlim_val)\n",
    "\n",
    "    # if (ylim_val is not None):\n",
    "    #     axes.ylim(ylim_val)\n",
    "\n",
    "    if created_fig:\n",
    "        plt.show()\n",
    "    \n",
    "    return axes\n",
    "\n",
    "\n",
    "\n",
    "def plot_item_columns(df,item,item_type='mmsi',columns=['latitude','longitude'], axes_size=(3, 2), separate_y=True,normalize=False,x_data_type='index',sort_columms = None,pre_process=None,xlim_val =None,ylim_val = None):\n",
    "    if not isinstance(item, list):\n",
    "        item = [item]\n",
    "\n",
    "    if columns is None:\n",
    "        raise ValueError(\"columns is empty\")\n",
    "    \n",
    "    elif not isinstance(columns,list):\n",
    "        columns = [columns]\n",
    "\n",
    "    fig, axes = create_subplot_scheme(axes_size=axes_size, num_axes=len(item))\n",
    "\n",
    "    # Plotting on the created subplots\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i > len(item):\n",
    "            break\n",
    "\n",
    "        # Assuming 'ships.get_item_df' is a function to filter the DataFrame by item\n",
    "        df_filt = get_item_df(df, item[i],item_type=item_type,sort_columns=sort_columms)\n",
    "\n",
    "        if (pre_process=='remove_bias'):\n",
    "            for column in columns:\n",
    "                df_filt.loc[:, column] = df_filt[column] - df_filt[column].mean()\n",
    "\n",
    "\n",
    "        plot_df_columns(df_filt,columns=columns,axes=ax,x_data_type=x_data_type,title=f'{item_type}={item[i]}',xlim_val=xlim_val,ylim_val=ylim_val)\n",
    "        \n",
    "        # # Plotting the specified columns\n",
    "        # for column in columns:\n",
    "        #     ax.plot(df_filt[column], label=column)\n",
    "        # ax.set_title(f'MMSI: {mmsi[i]}')\n",
    "        # ax.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plot_item_columns(df,item[1:3],item_type=item_type,x_data_type='index',columns=['longitude'],sort_columms=['time_seconds'],pre_process='remove_bias',ylim_val=ylim_val)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = info_df.sort_values(by='span_longitude',ascending=False)\n",
    "info_df1 = info_df.reset_index(drop=True)\n",
    "plot_df_columns(info_df1,columns=['span_longitude','num_mmsis'])\n",
    "pd.set_option('display.max_rows', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = get_item_df(df,info_df.index[17],item_type='mmsi',sort_columns='time')\n",
    "diff_data = df['time_seconds']\n",
    "plt.figure()\n",
    "plt.plot(diff_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at good ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_type = 'name'\n",
    "control_item_type = 'mmsi'\n",
    "info_df = info_df.sort_values('span_longitude')\n",
    "\n",
    "info_df_filter = {'len': ['>',10],\n",
    "                    f'num_{control_item_type}s':['==',1]}\n",
    "\n",
    "info_df_filt = filter_df(info_df,info_df_filter)\n",
    "\n",
    "item = info_df_filt.index[range(16)].tolist()\n",
    "ylim_val = [-info_df_filt['span_longitude'].max(),info_df_filt['span_longitude'].max()]\n",
    "plot_item_columns(df,item[1:3],item_type=item_type,x_data_type='index',columns=['longitude'],sort_columms=['time_seconds'],pre_process='remove_bias',ylim_val=ylim_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df_filt['span_longitude'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def normalize_columns(df, columns, method='min-max', add_norm_columns=True):\n",
    "    \"\"\"\n",
    "    Normalize specified columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the columns to be normalized.\n",
    "    columns (list or str): A list of column names or a single column name to normalize.\n",
    "    method (str): The normalization method to use ('min-max' or 'z-score').\n",
    "    add_norm_columns (bool): If True, adds normalized columns with suffix '_norm'. If False, replaces the original columns.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with normalized columns.\n",
    "    \"\"\"\n",
    "    # Ensure columns is a list\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "    \n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    for column in columns:\n",
    "        if method == 'min-max':\n",
    "            norm_col = (df[column] - df[column].min()) / (df[column].max() - df[column].min())\n",
    "        elif method == 'z-score':\n",
    "            norm_col = (df[column] - df[column].mean()) / df[column].std()\n",
    "        else:\n",
    "            raise ValueError(\"Method must be 'min-max' or 'z-score'\")\n",
    "        \n",
    "        if add_norm_columns:\n",
    "            df_normalized[column + '_norm'] = norm_col\n",
    "        else:\n",
    "            df_normalized[column] = norm_col\n",
    "    \n",
    "    return df_normalized\n",
    "\n",
    "# # Sample DataFrame\n",
    "# data = {\n",
    "#     'value1': [10, 20, 30, 40, 50],\n",
    "#     'value2': [5, 15, 25, 35, 45],\n",
    "#     'value3': [2, 4, 6, 8, 10]\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Normalize specified columns and add normalized columns\n",
    "# columns_to_normalize = ['value1', 'value2']\n",
    "# method = 'min-max'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(x, \n",
    "         marker_points=None, \n",
    "         marker_points_style = 'o',\n",
    "         marker_style=None, \n",
    "         line_style='-', \n",
    "         x_label='Index', \n",
    "         y_label='Value', \n",
    "         xlim=None, \n",
    "         ylim=None, \n",
    "         title='', \n",
    "         legend=True, \n",
    "         figsize=None, \n",
    "         color='blue',\n",
    "         ax=None):\n",
    "    \"\"\"\n",
    "    Plot the values of a NumPy array and optionally highlight marker_points.\n",
    "\n",
    "    Parameters:\n",
    "    x (np.ndarray): The NumPy array to plot.\n",
    "    marker_points (np.ndarray, optional): Indices of the marker_points to highlight. Default is None.\n",
    "    marker (str, optional): Marker style for the marker_points. Default is 'o'.\n",
    "    line_style (str, optional): Line style for the plot. Default is '-'.\n",
    "    x_label (str, optional): Label for the x-axis. Default is 'Index'.\n",
    "    y_label (str, optional): Label for the y-axis. Default is 'Value'.\n",
    "    xlim (tuple, optional): Limits for the x-axis in the form (xmin, xmax). Default is None.\n",
    "    ylim (tuple, optional): Limits for the y-axis in the form (ymin, ymax). Default is None.\n",
    "    title (str, optional): Title of the plot. Default is 'Plot of NumPy Array'.\n",
    "    legend (bool, optional): Whether to show a legend. Default is True.\n",
    "    figsize (tuple, optional): Size of the figure in the form (width, height). Default is None.\n",
    "    ax (matplotlib.axes.Axes, optional): Axes object to plot on. If None, a new figure and axes are created. Default is None.\n",
    "    \"\"\"\n",
    "    # Ensure x is a NumPy array\n",
    "    x = np.asarray(x)\n",
    "    \n",
    "    # Create a figure and axis if ax is not provided\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "    \n",
    "    # Plot the values\n",
    "    ax.plot(x, line_style, label='Data',marker=marker_style,color=color)\n",
    "    \n",
    "    # Highlight marker_points if provided\n",
    "    if marker_points is not None:\n",
    "        ax.plot(marker_points, x[marker_points], marker_points_style, linestyle='None', label='marker_points')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Set limits if provided\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "    \n",
    "    # Add a legend if required\n",
    "    if legend:\n",
    "        ax.legend()\n",
    "    \n",
    "    # Show the plot if a new figure was created\n",
    "    if ax is None:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# x = np.linspace(0, 10, 100)  # Create a NumPy array of 100 points from 0 to 10\n",
    "# y = np.sin(x)  # Compute the sine of each point\n",
    "\n",
    "# plot(y)  # Plot the sine wave\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "ship_df = get_item_df(df,item[0],item_type='name',sort_columns='time')\n",
    "ship_df = normalize_columns(ship_df,columns=['latitude'],method='min-max')\n",
    "\n",
    "x = np.array(ship_df['latitude_norm'])[1:]\n",
    "peak_points = find_peaks(x,distance=3)[0]\n",
    "plot (x,marker_points=peak_points,line_style='-',marker_style='*',marker_points_style='or')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot(x, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot the values of a NumPy array and optionally highlight marker_points.\n",
    "\n",
    "    Parameters:\n",
    "    x (np.ndarray): The NumPy array to plot.\n",
    "    kwargs (dict): Dictionary of optional parameters.\n",
    "        - marker_points (np.ndarray, optional): Indices of the marker_points to highlight. Default is None.\n",
    "        - marker_points_style (str, optional): Marker style for the marker_points. Default is 'o'.\n",
    "        - marker_style (str, optional): Marker style for the plot. Default is None.\n",
    "        - line_style (str, optional): Line style for the plot. Default is '-'.\n",
    "        - x_label (str, optional): Label for the x-axis. Default is 'Index'.\n",
    "        - y_label (str, optional): Label for the y-axis. Default is 'Value'.\n",
    "        - xlim (tuple, optional): Limits for the x-axis in the form (xmin, xmax). Default is None.\n",
    "        - ylim (tuple, optional): Limits for the y-axis in the form (ymin, ymax). Default is None.\n",
    "        - title (str, optional): Title of the plot. Default is ''.\n",
    "        - legend (bool, optional): Whether to show a legend. Default is True.\n",
    "        - figsize (tuple, optional): Size of the figure in the form (width, height). Default is None.\n",
    "        - color (str, optional): Color of the line. Default is 'blue'.\n",
    "        - ax (matplotlib.axes.Axes, optional): Axes object to plot on. If None, a new figure and axes are created. Default is None.\n",
    "    \"\"\"\n",
    "    # Set default values\n",
    "    params = {\n",
    "        'marker_points': None,\n",
    "        'marker_points_style': 'o',\n",
    "        'marker_style': None,\n",
    "        'line_style': '-',\n",
    "        'x_label': 'Index',\n",
    "        'y_label': 'Value',\n",
    "        'xlim': None,\n",
    "        'ylim': None,\n",
    "        'title': '',\n",
    "        'legend': True,\n",
    "        'figsize': None,\n",
    "        'color': 'blue',\n",
    "        'ax': None\n",
    "    }\n",
    "\n",
    "    # Update with any provided kwargs\n",
    "    params.update(kwargs)\n",
    "    \n",
    "    # Ensure x is a NumPy array\n",
    "    x = np.asarray(x)\n",
    "    \n",
    "    # Create a figure and axis if ax is not provided\n",
    "    if params['ax'] is None:\n",
    "        fig, ax = plt.subplots(figsize=params['figsize'])\n",
    "    else:\n",
    "        ax = params['ax']\n",
    "        fig = ax.figure\n",
    "    \n",
    "    # Plot the values\n",
    "    ax.plot(x, params['line_style'], label='Data', marker=params['marker_style'], color=params['color'])\n",
    "    \n",
    "    # Highlight marker_points if provided\n",
    "    if params['marker_points'] is not None:\n",
    "        ax.plot(params['marker_points'], x[params['marker_points']], params['marker_points_style'], linestyle='None', label='marker_points')\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(params['x_label'])\n",
    "    ax.set_ylabel(params['y_label'])\n",
    "    ax.set_title(params['title'])\n",
    "    \n",
    "    # Set limits if provided\n",
    "    if params['xlim'] is not None:\n",
    "        ax.set_xlim(params['xlim'])\n",
    "    if params['ylim'] is not None:\n",
    "        ax.set_ylim(params['ylim'])\n",
    "    \n",
    "    # Add a legend if required\n",
    "    if params['legend']:\n",
    "        ax.legend()\n",
    "    \n",
    "    # Show the plot if a new figure was created\n",
    "    if params['ax'] is None:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "x = np.linspace(0, 10, 100)  # Create a NumPy array of 100 points from 0 to 10\n",
    "y = np.sin(x)  # Compute the sine of each point\n",
    "\n",
    "plot(y, marker_points=np.array([10, 20, 30]), title='Sine Wave', color='green', marker_points_style='x', ylim=(-1.5, 1.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(**params):\n",
    "    default_params = {'a': 1, 'b': 2}\n",
    "    params = {**default_params, **params}  # Merge default_params with params\n",
    "    \n",
    "    a = params['a']\n",
    "    b = params['b']\n",
    "    c = a + b\n",
    "    return c\n",
    "\n",
    "\n",
    "def func2(**params):\n",
    "    default_params = {'a': 1, 'b': 10,'d':6}\n",
    "    params = {**default_params, **params}  # Merge default_params with params\n",
    "    \n",
    "    c = func(**params)\n",
    "    return c+params['d']\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Example usage\n",
    "result1 = func(a=5, b=10)\n",
    "print(result1)  # Output: 15\n",
    "\n",
    "params = {'a': 3, 'b': 7}\n",
    "result2 = func(**params)\n",
    "print(result2)  # Output: 10\n",
    "\n",
    "# Using default values\n",
    "result3 = func()\n",
    "print(result3)  # Output: 3\n",
    "\n",
    "# Mixing default and provided values\n",
    "result4 = func(a=4)\n",
    "print(result4)  # Output: 6\n",
    "\n",
    "\n",
    "\n",
    "result5 = func2(a=5,d=2)\n",
    "print(result5)  # Output: 6\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "20\n",
      "func2: Invalid value '20' for parameter 'd'. Allowed values are [2, 5, 10].\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "def parse_func_params(params, default_params):\n",
    "    parsed_params = {}\n",
    "\n",
    "    # Get the name of the calling function\n",
    "    calling_func_name = inspect.currentframe().f_back.f_code.co_name\n",
    "    \n",
    "    # Validate and parse each parameter\n",
    "    for param_name, param_info in default_params.items():\n",
    "        if isinstance(param_info, dict):\n",
    "            default_value = param_info.get('default')\n",
    "            allowed_values = param_info.get('optional', [])\n",
    "        else:\n",
    "            default_value = param_info\n",
    "            allowed_values = []\n",
    "\n",
    "        if param_name in params:\n",
    "            param_value = params[param_name]\n",
    "        else:\n",
    "            param_value = default_value\n",
    "\n",
    "        # Validate parameter value against allowed_values if provided\n",
    "        if allowed_values and param_value not in allowed_values:\n",
    "            raise ValueError(f\"{calling_func_name}: Invalid value '{param_value}' for parameter '{param_name}'. Allowed values are {sorted(allowed_values)}.\")\n",
    "\n",
    "        parsed_params[param_name] = param_value\n",
    "\n",
    "    return parsed_params\n",
    "\n",
    "\n",
    "def func1(**params):\n",
    "    # Define default and optional values for each parameter in default_params\n",
    "    default_params = {\n",
    "        'a': {'default': 5, 'optional': {5, 7, 3}},\n",
    "        'b': {'default': 10, 'optional': {2, 5, 10}}\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        params = parse_func_params(params, default_params)\n",
    "    except ValueError as e:\n",
    "        print(e)  # Print the exception message with calling stack path\n",
    "        return None\n",
    "\n",
    "    # Perform calculations using parsed parameters\n",
    "    a = params['a']\n",
    "    b = params['b']\n",
    "    c = a + b\n",
    "    return c\n",
    "\n",
    "def func2(e,g,**params):\n",
    "    # Define default and optional values for each parameter in default_params\n",
    "    default_params = {\n",
    "        'a': 5,\n",
    "        'd': {'default': 2, 'optional': {2, 5, 10}}\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        params = parse_func_params(params, default_params)\n",
    "    except ValueError as e:\n",
    "        print(e)  # Print the exception message with calling stack path\n",
    "        return None\n",
    "    \n",
    "    # Call func1 with validated params and perform additional calculation\n",
    "    f = func1(**params) + params['d']+e\n",
    "\n",
    "    return f\n",
    "\n",
    "# Example usage of func2\n",
    "result = func2(5,6,a=5, b=10)\n",
    "print(result)  # Output: 15\n",
    "\n",
    "params = {'a': 3, 'b': 10}  # 'a' and 'b' are not in allowed values, exception will be raised\n",
    "result = func2(5,6,**params)\n",
    "print(result)  # Output: None (error message with calling stack path printed)\n",
    "\n",
    "params = {'b': 5,'d':20}  # 'a' is not provided, func1 will receive 'b' from default_params and 'd' from default_params\n",
    "result = func2(5,6,**params)\n",
    "print(result)  # Output: None (error message with calling stack path printed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at bad ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "info_df_filter = {'len': ['>',10],\n",
    "                    'num_names':['>=',2]}\n",
    "\n",
    "info_df_filt = filter_df(info_df,info_df_filter)\n",
    "# display(info_df_filt)\n",
    "\n",
    "\n",
    "bad_mmsi = info_df_filt.index[range(16)].tolist()\n",
    "# plot_item_columns(df,mmsi,x_data_type='index',columns=['latitude','longitude','time_seconds'],sort_columms='latitued',pre_process='remove_bias')\n",
    "\n",
    "item_df = get_item_df(df,bad_mmsi[0])\n",
    "item_df['name'].unique()\n",
    "item_df = item_df.sort_values(by = 'name')\n",
    "plot_df_columns(item_df,columns='latitude')\n",
    "item_df.head(200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
